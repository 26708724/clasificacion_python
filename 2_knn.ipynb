{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_knn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67RBrvkUviuj"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Ejercicio de clasificación con vecinos cercanos (KNN)\n",
        "\n",
        "Ejemplo de clasificación utilizando vecinos cercanos para la clasificación de clientes y determinar que servicio ofrecerle a cada uno<br>\n",
        "\n",
        "v1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2sSeyEovSw-"
      },
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Szo7P_3v00C"
      },
      "source": [
        "# Recolectar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnVpNGuAvyFi"
      },
      "source": [
        "if os.access('Telecust1.csv', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/Telecust1.csv > Telecust1.csv\n",
        "    else:\n",
        "        !wget Telecust1.csv https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/Telecust1.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNSgxdfw0ix"
      },
      "source": [
        "### `Telecust1.csv.csv`:\n",
        "El dataset **`Telecust1.csv.csv`** contiene diferentes tipos de clientes que consumen un servicio de telecomunicación, los cuales deseamos clasificar en 4 categorias.<br> [Dataset source](https://www.kaggle.com/prathamtripathi/customersegmentation)\n",
        "\n",
        "- **region** --> region, ejemplo 2\n",
        "- **tenure** --> grado permanencia, ejemplo 40\n",
        "- **age** --> edad, ejemplo 52\n",
        "- **income** --> ingresos o sueldo, ejemplo 50 (un número que no representa una moneda real\n",
        "- **marital** --> si está casado o no\n",
        "- **address** --> dirección\n",
        "- **employ** --> empleo\n",
        "- **retire** --> si está retirado o no\n",
        "- **genero** --> 0 o 1 (no se sabe cual es cual)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHHsGe1Qypde"
      },
      "source": [
        "# Procesar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzaKBMbyoiy"
      },
      "source": [
        "df = pd.read_csv(\"Telecust1.csv\")\n",
        "des = df.describe()\n",
        "des.loc['Nan'] = df.isna().sum()\n",
        "des.loc['%Nan'] = (df.isna().mean())*100\n",
        "des"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw9HbE88y3wu"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LirgXKpiy8dr"
      },
      "source": [
        "print('Cantidad de datos en observacion:', df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnzYdlRzBxz"
      },
      "source": [
        "# Explorar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2w_eW5QI-hf"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH6oDykAzBMG"
      },
      "source": [
        "# Exploramos que tan balanceado está el dataset,\n",
        "# como está repartida las categorias entre los clientes actuales\n",
        "df['custcat'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5cQJRWdzTk3"
      },
      "source": [
        "ax = sns.countplot(data=df, x=\"custcat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqVWUXPm0op-"
      },
      "source": [
        "Se puede ver que el dataset está bastante balanceado, no habrá una tendencia marcada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ-1cgavIns4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f1b4PBcJAWU"
      },
      "source": [
        "# Nos quedamos con aquellas columnas que podemos entender su relacion con el objetivo\n",
        "df_clean = df[['tenure', 'age', 'income', 'marital', 'retire', 'gender', 'custcat']]\n",
        "df_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdfLMthm0yyY"
      },
      "source": [
        "#### Normalización de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqEKDZw0KETM"
      },
      "source": [
        "Analizar cual es la distribución de los datos numéricos\n",
        "- tenure\n",
        "- age\n",
        "- income"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJlDmX_F1ksA"
      },
      "source": [
        "sns.displot(data=df_clean, x='age')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X2CcMqdJ7z6"
      },
      "source": [
        "sns.displot(data=df_clean, x='tenure')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xCksVi5J_V2"
      },
      "source": [
        "sns.displot(data=df_clean, x='income')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d6BDobHKLHy"
      },
      "source": [
        "El \"ingreso\" sigue una distribución normal pero con muchos outliers, es por eso que no utilizaremos el MinMaxScaler sino que se utilizará el StandardScaler a pesar de que \"tenure\" no siga una distribución normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc6xNfbgKj4y"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "df_norm = df_clean.copy()\n",
        "age_scaler = StandardScaler()\n",
        "tenure_scaler = StandardScaler()\n",
        "income_scaler = StandardScaler()\n",
        "df_norm.loc[:, 'age'] = age_scaler.fit_transform(df[['age']])\n",
        "df_norm.loc[:, 'tenure'] = tenure_scaler.fit_transform(df[['tenure']])\n",
        "df_norm.loc[:, 'income'] = income_scaler.fit_transform(df[['income']])\n",
        "df_norm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z_SuZlj3gbQ"
      },
      "source": [
        "# Entrenar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntY84fHj3q5q"
      },
      "source": [
        "El primer paso es obtener los datos que serán la entrada del sistema (X) y los datos que serán la salida del modelo estimador (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIg2_OQ43fqZ"
      },
      "source": [
        "X = df_norm.drop('custcat', axis=1).values\n",
        "y = df_norm['custcat'].values\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbr-SnON4LuM"
      },
      "source": [
        "Siguiente paso es dividir el dataset en entrenamiento (train) y evaluación (test). Utilizaremos el criterio 70%30%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVD4YkjS4MW2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Fijamos un \"random_state\" constante para que siempre el dataset se parta de la misma forma\n",
        "# para poder repetir los ensayos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgF8oPBe7XMi"
      },
      "source": [
        "# Creamos el modelo base\n",
        "class RandomBaseModel():\n",
        "    def __init__(self):\n",
        "        self.classes_ = [0, 1]\n",
        "    def fit(self,X, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        return None\n",
        "\n",
        "    def predict(self,X):\n",
        "        rand = np.random.randint(0, len(self.classes_), size=X.shape[0])\n",
        "        rand_clases = [self.classes_[x] for x in rand]\n",
        "        return np.asarray(rand_clases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeYi3FSi7bGW"
      },
      "source": [
        "# Obtener la salida según el modelo base\n",
        "random_model = RandomBaseModel()\n",
        "random_model.fit(X_train, y_train)\n",
        "y_hat_base = random_model.predict(X_test)\n",
        "random_model.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBh2fSnT4SED"
      },
      "source": [
        "#### Crear un modelo de clasificación con vecinos cercanos (KNN)\n",
        "Parámetros\n",
        "- n_neighbors --> (k) número de vecinos cercanos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRw2jgPl4Xuc"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "K_MAX = 20\n",
        "mean_acc = np.zeros((K_MAX))\n",
        "\n",
        "for i in range(K_MAX):\n",
        "    # Entrenar el modelo\n",
        "    clf = KNeighborsClassifier(n_neighbors=(i+1)).fit(X_train,y_train)\n",
        "\n",
        "    # Prediccion\n",
        "    y_hat = clf.predict(X_test)   \n",
        "\n",
        "    # Evaluar el modelo\n",
        "    mean_acc[i] = accuracy_score(y_test, y_hat)\n",
        "\n",
        "plt.plot(range(1, K_MAX+1), mean_acc,'darkBlue')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('K')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"La mejor exactitud se obtuvo con {mean_acc.max():.2f} con K={mean_acc.argmax()+1}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL0_TMz7Em4o"
      },
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=13).fit(X_train,y_train)\n",
        "y_hat = clf.predict(X_test)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3IfjUuI4XnD"
      },
      "source": [
        "# Validar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzBGdQS67eAq"
      },
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_hat_base, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMKONtv55zL8"
      },
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_hat, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeLeYLYz6ZhO"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_hat)\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n",
        "cmd.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZxGbjG96jR"
      },
      "source": [
        "# Utilizar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6euFUIFDRbmP"
      },
      "source": [
        "# Supongamos que deseamos ver a que categoría pertenecemos\n",
        "# dado los siguientes datos\n",
        "age = 25\n",
        "tenure = 4\n",
        "income = df['income'].mean() # ganamos el promedio\n",
        "marital = 0 # no estamos casados\n",
        "retire = 0 # no estamos retirados\n",
        "gender = 1 # solo algun genero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e01cqkzTS8n3"
      },
      "source": [
        "# El scaler espera como entrada una matriz (filas y columnas)\n",
        "# Por eso el doble corchete\n",
        "age_numpy = np.array([[age]])\n",
        "# Utilizamos float para convertir la matriz que retorna el scaler\n",
        "# a un número\n",
        "age_norm = float(age_scaler.transform(age_numpy))\n",
        "tenure_norm = float(tenure_scaler.transform(np.array([[tenure]])))\n",
        "income_norm = float(income_scaler.transform(np.array([[income]])))\n",
        "# El sistema espera como entrada \"X\" en este caso una sola fila pero varias\n",
        "# columnas, por eso el reshape(1, -1) donde el \"-1\" significa \"varias\"\n",
        "# (el sistema determina cuantas)\n",
        "X_prueba = np.array([tenure_norm, age_norm, income_norm, marital, retire, gender]).reshape(1, -1)\n",
        "print('Shape:', X_prueba.shape)\n",
        "print('Valores:\\n', X_prueba)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYimWR0FTwK-"
      },
      "source": [
        "mi_categoria = clf.predict(X_prueba)\n",
        "mi_categoria"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yzVZcZ9-4m"
      },
      "source": [
        "# Conclusión\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWAReOgo-B7b"
      },
      "source": [
        "En este ejemplo se obtuvo muy poca performance, pero se pudo ver como comparar muchos modelos KNN con distintos \"K\" y a su vez como ingresar un dato nuevo para predecir una categoría. Se podría probar con otros clasificadores pero el problema radica en la falta de datos"
      ]
    }
  ]
}